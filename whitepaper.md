# ERA Decision & Arbitration Layer
## Надёжное принятие решений на базе ансамбля LLM

### Аннотация

Современные большие языковые модели (LLM) демонстрируют впечатляющие способности
к рассуждению и синтезу текста, но остаются по своей природе стохастичными.
Одна и та же модель может дать разные ответы на идентичный запрос, уверенно
формулировать ошибочные выводы и плохо сигнализировать границы собственной применимости.

Это делает использование LLM в научных, медицинских и финансовых решениях рискованным.

В данной работе представлен архитектурный подход **ERA Decision & Arbitration Layer (DAL)** —
систему принятия решений, сочетающую:

- параллельный ансамбль 5–12 независимых LLM (solvers),
- модель-арбитр для оценки качества без пересчёта,
- автоматический консенсус (top-2 / top-3),
- раунд самокритики (rebuttal) при высоком разброе,
- многократные прогоны с доверительными интервалами (Wilson CI),
- адаптивную память качества моделей (ERA-style eval layer).

**Результат**: надёжные, воспроизводимые и проверяемые интеллектуальные решения.

---

## 1. Мотивация: Проблема одиночных LLM

### Нестабильность
```
Query: "Объясни фотосинтез"
Response 1 (Run 1): "Фотосинтез — это... [A]"
Response 2 (Run 2): "Фотосинтез — это... [B]"
Similarity: 60%
```

### Галлюцинации
Модель уверенно формулирует ошибочные факты, не сигнализируя неопределённость.

### Отсутствие мета-знания
LLM редко явно указывают:
- На какие допущения опирается ответ?
- Где ответ может быть неточен?
- Насколько уверена модель?

---

## 2. Решение: Ансамблевый подход

Вместо одной модели используется пул из N ≥ 5 независимых LLM:

| Роль | Примеры |
|------|---------|
| Логические | GPT-4 Turbo, Claude-3 Opus |
| Объяснительные | Llama 3 70B, Gemini |
| Критические | DeepSeek, Mistral Large |
| Быстрые | Smaller models |

Каждая модель формирует структурированный ответ:

```json
{
  "final_answer": "...",
  "confidence": 0.82,
  "assumptions": ["A1", "A2"],
  "risks": ["R1", "R2"],
  "evidence": ["E1", "E2"],
  "self_checks": ["S1", "S2"]
}
```

---

## 3. Процесс: Раунды и режимы

### Раунд 1: Solver Pool
- N моделей запускаются параллельно
- Каждая генерирует структурированный JSON
- Считается disagreement_rate (% уникальных ответов)

### Раунд 2: Arbiter Ranker
- Отдельная модель-арбитр оценивает качество (НЕ решает заново)
- Критерии: непротиворечивость, соответствие условиям, риск-осознанность
- Ранжирует от top-1 до top-N

### Раунд 3 (опционально): Consensus Synthesizer
- Если gap(top1, top2) < ε → синтезирует финальный ответ из top-K
- Сохраняет правильные части, разрешает противоречия явно

### Раунд 4 (условно): Rebuttal
- Если disagreement ≥ threshold → второй круг
- Каждый solver критикует остальные и улучшает свой ответ
- Повторный арбитраж

---

## 4. Метрики качества и доверия

### Disagreement Rate
```
disagreement_rate = unique_answers / N
```

Высокий disagreement → включить rebuttal.

### Confidence Interval (Wilson)

После K прогонов считается 95% доверительный интервал:

```
p_CI = (p + z²/2n) / (1 + z²/n) ± z * sqrt((p(1-p) + z²/4n²) / n) / (1 + z²/n)
```

Где:
- p = success_rate
- n = number of runs
- z = 1.96 (для 95%)

**Результат**: "Система стабильно выбирает одно решение с 80% вероятностью (95% CI: [60%, 95%])"

---

## 5. Адаптация: Model Memory (ERA-style Eval Layer)

После каждого запуска система обновляет reliability каждой модели:

```
reliability_{t+1} = (1 - α) * reliability_t + α * reward_t
```

Где:
- reward = 1.0, если модель в финальном решении; 0.0 иначе
- α = 0.05 (learning rate)

Это позволяет системе:
- Адаптироваться к вашему домену
- Отучить низкокачественные модели
- Учить высококачественные

---

## 6. Интеграция в мультиагентные системы

ERA DAL работает как **Decision & Arbitration Layer**:

```
Agents (гипотезы) → ERA DAL (оценка + выбор) → Executors (действие)
```

**Input контракт:**

```json
{
  "domain": "science",
  "problem": "Объясни...",
  "policy": {
    "pool_size": 7,
    "consensus_topk": 3,
    "epsilon": 0.07,
    "rebuttal": true,
    "repeats": 5
  }
}
```

**Output контракт:**

```json
{
  "final_answer": "...",
  "decision_mode": "consensus_top3",
  "used_candidates": ["model_id_1", "model_id_2"],
  "ranking": [...],
  "stability": {
    "majority_rate": 0.8,
    "ci_lower": 0.6,
    "ci_upper": 0.95
  }
}
```

---

## 7. Результаты и примеры

### Пример 1: Научный вопрос
```
Task: "Объясни вторую закон Ньютона"
Pool: science (7 моделей)
Repeats: 5

Результат:
- Decision mode: consensus_top3
- Majority rate: 85% (95% CI: [72%, 94%])
- Reliability history: GPT-4 (0.78) > Claude (0.72) > Llama (0.65)
```

### Пример 2: Экономический вопрос
```
Task: "Как инфляция влияет на реальную ставку..."
Pool: econ (6 моделей)
Repeats: 5

Результат:
- Decision mode: hard_select (gap > epsilon)
- Stability: 70% (требуется улучшение)
- Action: Увеличить repeats или пересмотреть epsilon
```

---

## 8. Ограничения и развитие

### Ограничения
1. **Стоимость** выше, чем одна модель (но часто окупается качеством)
2. **Латентность** — параллельный запуск даёт выигрыш в 3–7×
3. **Доменная специфика** — нужна калибровка под задачу

### Развитие (roadmap)
- [ ] REST API и интеграция с внешними оркестраторами
- [ ] Формальные метрики корректности (BLEU, ROUGE, Levenshtein)
- [ ] Dashboard для мониторинга reliability по доменам
- [ ] Asyncio для полного распараллеливания
- [ ] Fine-tuned arbiter для вашего домена

---

## 9. Заключение

Ансамблевый арбитраж LLM — практический шаг от "умного текста"
к управляемым, воспроизводимым и проверяемым интеллектуальным системам.

Система обеспечивает:
- Надёжность через ансамбль
- Прозрачность через структурированные выходы
- Доверие через статистику
- Адаптивность через memory

**Применимо для**: научных Q&A, экономических прогнозов, медицинских консультаций,
логистических решений и других критичных по точности задач.

---

**Автор:** ERA Team  
**Версия:** 1.0.0  
**Дата:** 2025-12-14
